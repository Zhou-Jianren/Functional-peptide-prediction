{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('F:/Work/Experiment/pLM4ACE/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 320)\n",
      "(1020, 1)\n",
      "394\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"fusion_features/Data/single/ESM.csv\", index_col=0, header=None)\n",
    "labels = pd.read_csv(\"fusion_features/Data/label.csv\", index_col=False, header=None)\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(np.count_nonzero(labels==0))\n",
    "print(np.count_nonzero(labels==1))\n",
    "\n",
    "feature = np.array(features)\n",
    "label = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# model\n",
    "def get_GRU_model(input_dim, out_dim, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(64, return_sequences=True, input_shape=(1, input_dim)))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(GRU(64, return_sequences=True))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu', name=\"Dense_128\"))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(2, activation='softmax', name=\"Dense_2\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(learning_rate), metrics=['binary_accuracy'])  # rmsprop\n",
    "    return model\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the model\n",
    "model_save_dir = 'save_models/1020_i'\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "13/13 [==============================] - 7s 19ms/step - loss: 0.6760 - binary_accuracy: 0.6029\n",
      "Epoch 2/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6586 - binary_accuracy: 0.6225\n",
      "Epoch 3/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6468 - binary_accuracy: 0.6225\n",
      "Epoch 4/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.6319 - binary_accuracy: 0.6225\n",
      "Epoch 5/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.6041 - binary_accuracy: 0.6532\n",
      "Epoch 6/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5657 - binary_accuracy: 0.7267\n",
      "Epoch 7/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5136 - binary_accuracy: 0.7806\n",
      "Epoch 8/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4714 - binary_accuracy: 0.7855\n",
      "Epoch 9/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4478 - binary_accuracy: 0.8002\n",
      "Epoch 10/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4189 - binary_accuracy: 0.8125\n",
      "Epoch 11/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3981 - binary_accuracy: 0.8174\n",
      "Epoch 12/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3964 - binary_accuracy: 0.8235\n",
      "Epoch 13/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3751 - binary_accuracy: 0.8248\n",
      "Epoch 14/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3614 - binary_accuracy: 0.8395\n",
      "Epoch 15/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3589 - binary_accuracy: 0.8382\n",
      "Epoch 16/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3381 - binary_accuracy: 0.8444\n",
      "Epoch 17/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3253 - binary_accuracy: 0.8505\n",
      "Epoch 18/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3205 - binary_accuracy: 0.8554\n",
      "Epoch 19/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3131 - binary_accuracy: 0.8566\n",
      "Epoch 20/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2874 - binary_accuracy: 0.8640\n",
      "Epoch 21/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2966 - binary_accuracy: 0.8640\n",
      "Epoch 22/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2871 - binary_accuracy: 0.8640\n",
      "Epoch 23/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2847 - binary_accuracy: 0.8713\n",
      "Epoch 24/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2625 - binary_accuracy: 0.8848\n",
      "Epoch 25/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2557 - binary_accuracy: 0.8873\n",
      "Epoch 26/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2462 - binary_accuracy: 0.8958\n",
      "Epoch 27/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2297 - binary_accuracy: 0.8995\n",
      "Epoch 28/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2383 - binary_accuracy: 0.8971\n",
      "Epoch 29/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2372 - binary_accuracy: 0.8922\n",
      "Epoch 30/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2440 - binary_accuracy: 0.8873\n",
      "Epoch 31/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2071 - binary_accuracy: 0.9020\n",
      "Epoch 32/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2154 - binary_accuracy: 0.9032\n",
      "Epoch 33/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1958 - binary_accuracy: 0.9203\n",
      "Epoch 34/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2128 - binary_accuracy: 0.9007\n",
      "Epoch 35/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2167 - binary_accuracy: 0.9093\n",
      "Epoch 36/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2163 - binary_accuracy: 0.9105\n",
      "Epoch 37/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2092 - binary_accuracy: 0.9044\n",
      "Epoch 38/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1772 - binary_accuracy: 0.9277\n",
      "Epoch 39/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1780 - binary_accuracy: 0.9277\n",
      "Epoch 40/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1676 - binary_accuracy: 0.9363\n",
      "Epoch 41/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1750 - binary_accuracy: 0.9203\n",
      "Epoch 42/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1609 - binary_accuracy: 0.9277\n",
      "Epoch 43/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1586 - binary_accuracy: 0.9338\n",
      "Epoch 44/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1550 - binary_accuracy: 0.9363\n",
      "Epoch 45/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1504 - binary_accuracy: 0.9363\n",
      "Epoch 46/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1853 - binary_accuracy: 0.9228\n",
      "Epoch 47/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1550 - binary_accuracy: 0.9326\n",
      "Epoch 48/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1451 - binary_accuracy: 0.9485\n",
      "Epoch 49/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1494 - binary_accuracy: 0.9350\n",
      "Epoch 50/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1324 - binary_accuracy: 0.9449\n",
      "Epoch 51/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1354 - binary_accuracy: 0.9461\n",
      "Epoch 52/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1380 - binary_accuracy: 0.9485\n",
      "Epoch 53/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1495 - binary_accuracy: 0.9400\n",
      "Epoch 54/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1372 - binary_accuracy: 0.9449\n",
      "Epoch 55/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1288 - binary_accuracy: 0.9559\n",
      "Epoch 56/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1264 - binary_accuracy: 0.9571\n",
      "Epoch 57/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1164 - binary_accuracy: 0.9620\n",
      "Epoch 58/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1167 - binary_accuracy: 0.9485\n",
      "Epoch 59/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1345 - binary_accuracy: 0.9400\n",
      "Epoch 60/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1325 - binary_accuracy: 0.9498\n",
      "Epoch 61/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1302 - binary_accuracy: 0.9522\n",
      "Epoch 62/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1394 - binary_accuracy: 0.9400\n",
      "Epoch 63/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1197 - binary_accuracy: 0.9436\n",
      "Epoch 64/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1331 - binary_accuracy: 0.9485\n",
      "Epoch 65/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1205 - binary_accuracy: 0.9547\n",
      "Epoch 66/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1316 - binary_accuracy: 0.9412\n",
      "Epoch 67/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1159 - binary_accuracy: 0.9534\n",
      "Epoch 68/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0969 - binary_accuracy: 0.9632\n",
      "Epoch 69/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1062 - binary_accuracy: 0.9583\n",
      "Epoch 70/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1027 - binary_accuracy: 0.9596\n",
      "Epoch 71/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0922 - binary_accuracy: 0.9694\n",
      "Epoch 72/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1106 - binary_accuracy: 0.9583\n",
      "Epoch 73/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0992 - binary_accuracy: 0.9669\n",
      "Epoch 74/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1026 - binary_accuracy: 0.9571\n",
      "Epoch 75/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0876 - binary_accuracy: 0.9645\n",
      "Epoch 76/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0918 - binary_accuracy: 0.9620\n",
      "Epoch 77/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0869 - binary_accuracy: 0.9669\n",
      "Epoch 78/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0946 - binary_accuracy: 0.9632\n",
      "Epoch 79/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0963 - binary_accuracy: 0.9657\n",
      "Epoch 80/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0940 - binary_accuracy: 0.9694\n",
      "Epoch 81/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1331 - binary_accuracy: 0.9387\n",
      "Epoch 82/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1292 - binary_accuracy: 0.9498\n",
      "Epoch 83/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0886 - binary_accuracy: 0.9657\n",
      "Epoch 84/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0838 - binary_accuracy: 0.9669\n",
      "Epoch 85/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0868 - binary_accuracy: 0.9608\n",
      "Epoch 86/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1087 - binary_accuracy: 0.9534\n",
      "Epoch 87/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0951 - binary_accuracy: 0.9608\n",
      "Epoch 88/120\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0864 - binary_accuracy: 0.9730\n",
      "Epoch 89/120\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0970 - binary_accuracy: 0.9583\n",
      "Epoch 90/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0822 - binary_accuracy: 0.9694\n",
      "Epoch 91/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0998 - binary_accuracy: 0.9583\n",
      "Epoch 92/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0756 - binary_accuracy: 0.9743\n",
      "Epoch 93/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0817 - binary_accuracy: 0.9657\n",
      "Epoch 94/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0784 - binary_accuracy: 0.9694\n",
      "Epoch 95/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0760 - binary_accuracy: 0.9767\n",
      "Epoch 96/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0784 - binary_accuracy: 0.9669\n",
      "Epoch 97/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0794 - binary_accuracy: 0.9681\n",
      "Epoch 98/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0893 - binary_accuracy: 0.9657\n",
      "Epoch 99/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0714 - binary_accuracy: 0.9743\n",
      "Epoch 100/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0749 - binary_accuracy: 0.9743\n",
      "Epoch 101/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0905 - binary_accuracy: 0.9681\n",
      "Epoch 102/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0904 - binary_accuracy: 0.9571\n",
      "Epoch 103/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0751 - binary_accuracy: 0.9681\n",
      "Epoch 104/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0696 - binary_accuracy: 0.9779\n",
      "Epoch 105/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0623 - binary_accuracy: 0.9804\n",
      "Epoch 106/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0698 - binary_accuracy: 0.9694\n",
      "Epoch 107/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0559 - binary_accuracy: 0.9853\n",
      "Epoch 108/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0678 - binary_accuracy: 0.9718\n",
      "Epoch 109/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0626 - binary_accuracy: 0.9779\n",
      "Epoch 110/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9412\n",
      "Epoch 111/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1031 - binary_accuracy: 0.9596\n",
      "Epoch 112/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0604 - binary_accuracy: 0.9792\n",
      "Epoch 113/120\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0656 - binary_accuracy: 0.9779\n",
      "Epoch 114/120\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0624 - binary_accuracy: 0.9792\n",
      "Epoch 115/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0760 - binary_accuracy: 0.9669\n",
      "Epoch 116/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0533 - binary_accuracy: 0.9841\n",
      "Epoch 117/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0521 - binary_accuracy: 0.9816\n",
      "Epoch 118/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0490 - binary_accuracy: 0.9841\n",
      "Epoch 119/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0518 - binary_accuracy: 0.9853\n",
      "Epoch 120/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0606 - binary_accuracy: 0.9755\n",
      "Epoch 1/120\n",
      "13/13 [==============================] - 4s 27ms/step - loss: 0.6745 - binary_accuracy: 0.6189\n",
      "Epoch 2/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6538 - binary_accuracy: 0.6225\n",
      "Epoch 3/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6415 - binary_accuracy: 0.6225\n",
      "Epoch 4/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6196 - binary_accuracy: 0.6225\n",
      "Epoch 5/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5862 - binary_accuracy: 0.6593\n",
      "Epoch 6/120\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.5419 - binary_accuracy: 0.7610\n",
      "Epoch 7/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4991 - binary_accuracy: 0.7892\n",
      "Epoch 8/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4640 - binary_accuracy: 0.8027\n",
      "Epoch 9/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4358 - binary_accuracy: 0.7990\n",
      "Epoch 10/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4066 - binary_accuracy: 0.8199\n",
      "Epoch 11/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3821 - binary_accuracy: 0.8284\n",
      "Epoch 12/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3734 - binary_accuracy: 0.8284\n",
      "Epoch 13/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3563 - binary_accuracy: 0.8358\n",
      "Epoch 14/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3402 - binary_accuracy: 0.8419\n",
      "Epoch 15/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3326 - binary_accuracy: 0.8493\n",
      "Epoch 16/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3161 - binary_accuracy: 0.8578\n",
      "Epoch 17/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3215 - binary_accuracy: 0.8456\n",
      "Epoch 18/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3264 - binary_accuracy: 0.8517\n",
      "Epoch 19/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3285 - binary_accuracy: 0.8419\n",
      "Epoch 20/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3056 - binary_accuracy: 0.8738\n",
      "Epoch 21/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2809 - binary_accuracy: 0.8860\n",
      "Epoch 22/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2831 - binary_accuracy: 0.8750\n",
      "Epoch 23/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2723 - binary_accuracy: 0.8775\n",
      "Epoch 24/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2661 - binary_accuracy: 0.8775\n",
      "Epoch 25/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2563 - binary_accuracy: 0.8958\n",
      "Epoch 26/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2491 - binary_accuracy: 0.8934\n",
      "Epoch 27/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2421 - binary_accuracy: 0.8909\n",
      "Epoch 28/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2386 - binary_accuracy: 0.8860\n",
      "Epoch 29/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2219 - binary_accuracy: 0.8958\n",
      "Epoch 30/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2179 - binary_accuracy: 0.8995\n",
      "Epoch 31/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2081 - binary_accuracy: 0.9105\n",
      "Epoch 32/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2125 - binary_accuracy: 0.9032\n",
      "Epoch 33/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2255 - binary_accuracy: 0.8971\n",
      "Epoch 34/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2029 - binary_accuracy: 0.9044\n",
      "Epoch 35/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1981 - binary_accuracy: 0.9118\n",
      "Epoch 36/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1920 - binary_accuracy: 0.9167\n",
      "Epoch 37/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1858 - binary_accuracy: 0.9191\n",
      "Epoch 38/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1809 - binary_accuracy: 0.9289\n",
      "Epoch 39/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1908 - binary_accuracy: 0.9142\n",
      "Epoch 40/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1775 - binary_accuracy: 0.9240\n",
      "Epoch 41/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1829 - binary_accuracy: 0.9167\n",
      "Epoch 42/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1820 - binary_accuracy: 0.9228\n",
      "Epoch 43/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1559 - binary_accuracy: 0.9400\n",
      "Epoch 44/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1602 - binary_accuracy: 0.9363\n",
      "Epoch 45/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1532 - binary_accuracy: 0.9326\n",
      "Epoch 46/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1478 - binary_accuracy: 0.9301\n",
      "Epoch 47/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1564 - binary_accuracy: 0.9350\n",
      "Epoch 48/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1586 - binary_accuracy: 0.9350\n",
      "Epoch 49/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1634 - binary_accuracy: 0.9301\n",
      "Epoch 50/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1634 - binary_accuracy: 0.9350\n",
      "Epoch 51/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1364 - binary_accuracy: 0.9473\n",
      "Epoch 52/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1448 - binary_accuracy: 0.9350\n",
      "Epoch 53/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1450 - binary_accuracy: 0.9363\n",
      "Epoch 54/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1377 - binary_accuracy: 0.9461\n",
      "Epoch 55/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1301 - binary_accuracy: 0.9485\n",
      "Epoch 56/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1332 - binary_accuracy: 0.9498\n",
      "Epoch 57/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1224 - binary_accuracy: 0.9559\n",
      "Epoch 58/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1427 - binary_accuracy: 0.9326\n",
      "Epoch 59/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1371 - binary_accuracy: 0.9461\n",
      "Epoch 60/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1325 - binary_accuracy: 0.9449\n",
      "Epoch 61/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1538 - binary_accuracy: 0.9375\n",
      "Epoch 62/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1674 - binary_accuracy: 0.9289\n",
      "Epoch 63/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1202 - binary_accuracy: 0.9449\n",
      "Epoch 64/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1200 - binary_accuracy: 0.9485\n",
      "Epoch 65/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1165 - binary_accuracy: 0.9583\n",
      "Epoch 66/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1205 - binary_accuracy: 0.9510\n",
      "Epoch 67/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1124 - binary_accuracy: 0.9534\n",
      "Epoch 68/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1087 - binary_accuracy: 0.9534\n",
      "Epoch 69/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1593 - binary_accuracy: 0.9326\n",
      "Epoch 70/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1415 - binary_accuracy: 0.9424\n",
      "Epoch 71/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1102 - binary_accuracy: 0.9571\n",
      "Epoch 72/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1000 - binary_accuracy: 0.9632\n",
      "Epoch 73/120\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1032 - binary_accuracy: 0.9596\n",
      "Epoch 74/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1126 - binary_accuracy: 0.9583\n",
      "Epoch 75/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0919 - binary_accuracy: 0.9632\n",
      "Epoch 76/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0968 - binary_accuracy: 0.9608\n",
      "Epoch 77/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1091 - binary_accuracy: 0.9583\n",
      "Epoch 78/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0893 - binary_accuracy: 0.9657\n",
      "Epoch 79/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0953 - binary_accuracy: 0.9620\n",
      "Epoch 80/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1114 - binary_accuracy: 0.9473\n",
      "Epoch 81/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1284 - binary_accuracy: 0.9449\n",
      "Epoch 82/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1072 - binary_accuracy: 0.9632\n",
      "Epoch 83/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1011 - binary_accuracy: 0.9657\n",
      "Epoch 84/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0829 - binary_accuracy: 0.9730\n",
      "Epoch 85/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0853 - binary_accuracy: 0.9669\n",
      "Epoch 86/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0960 - binary_accuracy: 0.9645\n",
      "Epoch 87/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0829 - binary_accuracy: 0.9718\n",
      "Epoch 88/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0827 - binary_accuracy: 0.9694\n",
      "Epoch 89/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0788 - binary_accuracy: 0.9755\n",
      "Epoch 90/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0752 - binary_accuracy: 0.9755\n",
      "Epoch 91/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0953 - binary_accuracy: 0.9657\n",
      "Epoch 92/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0870 - binary_accuracy: 0.9596\n",
      "Epoch 93/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0726 - binary_accuracy: 0.9743\n",
      "Epoch 94/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0886 - binary_accuracy: 0.9706\n",
      "Epoch 95/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0938 - binary_accuracy: 0.9669\n",
      "Epoch 96/120\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.0962 - binary_accuracy: 0.9534\n",
      "Epoch 97/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0770 - binary_accuracy: 0.9718\n",
      "Epoch 98/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0702 - binary_accuracy: 0.9779\n",
      "Epoch 99/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0697 - binary_accuracy: 0.9669\n",
      "Epoch 100/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0796 - binary_accuracy: 0.9657\n",
      "Epoch 101/120\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0714 - binary_accuracy: 0.9694\n",
      "Epoch 102/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0739 - binary_accuracy: 0.9730\n",
      "Epoch 103/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0873 - binary_accuracy: 0.9669\n",
      "Epoch 104/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0882 - binary_accuracy: 0.9645\n",
      "Epoch 105/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0693 - binary_accuracy: 0.9743\n",
      "Epoch 106/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0679 - binary_accuracy: 0.9804\n",
      "Epoch 107/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0646 - binary_accuracy: 0.9718\n",
      "Epoch 108/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0700 - binary_accuracy: 0.9743\n",
      "Epoch 109/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0677 - binary_accuracy: 0.9792\n",
      "Epoch 110/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0829 - binary_accuracy: 0.9669\n",
      "Epoch 111/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0578 - binary_accuracy: 0.9767\n",
      "Epoch 112/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0539 - binary_accuracy: 0.9767\n",
      "Epoch 113/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0555 - binary_accuracy: 0.9779\n",
      "Epoch 114/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0471 - binary_accuracy: 0.9816\n",
      "Epoch 115/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1015 - binary_accuracy: 0.9498\n",
      "Epoch 116/120\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1069 - binary_accuracy: 0.9571\n",
      "Epoch 117/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1044 - binary_accuracy: 0.9510\n",
      "Epoch 118/120\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0729 - binary_accuracy: 0.9706\n",
      "Epoch 119/120\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0570 - binary_accuracy: 0.9841\n",
      "Epoch 120/120\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0555 - binary_accuracy: 0.9767\n",
      "BACC: 0.931 ± 0.003\n",
      "Sn: 0.973 ± 0.0\n",
      "Sp: 0.889 ± 0.005\n",
      "MCC: 0.838 ± 0.007\n",
      "AUC: 0.965 ± 0.0\n",
      "AP: 0.967 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "[sample_num, input_dim] = np.shape(feature)\n",
    "X = np.reshape(feature, (-1,1,input_dim))\n",
    "\n",
    "y = label\n",
    "out_dim=2\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "\n",
    "losses = []  # Used to store the loss value of each fold\n",
    "for i in range(2):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "    y_train_whole = to_categorical(y_train_whole)\n",
    "    \n",
    "    clf = get_GRU_model(input_dim, out_dim, 0.0005)\n",
    "    hist = clf.fit(X_train_whole, y_train_whole, batch_size=64, epochs=120)\n",
    "\n",
    "    # save model\n",
    "    # model_path = os.path.join(model_save_dir, f'ESM_GRU_{i}.h5')\n",
    "    # clf.save(model_path)\n",
    "    # print(f'Model for fold {i+1} saved at {model_path}')\n",
    "\n",
    "    losses.append(hist.history['loss'])  # Record the loss value of each epoch\n",
    "\n",
    "    y_score = clf.predict(X_ind_test)\n",
    "    y_class = categorical_probas_to_classes(y_score)\n",
    "    TP, FP, FN, TN = confusion_matrix(y_ind_test, y_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_ind_test, y_score[:, 1])\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    AUC_collecton.append(auc_roc)\n",
    "    # PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_ind_test, y_score[:, 1])\n",
    "    average_precision = average_precision_score(y_ind_test, y_score[:, 1])\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "    mean_precision = np.interp(mean_recall, recall, precision)\n",
    "    all_precision.append(mean_precision)\n",
    "    AP.append(average_precision)\n",
    "\n",
    "\n",
    "# After all cross-validation cycles are completed, the mean TPR is calculated.\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# Output\n",
    "results = [\n",
    "    f\"BACC: {round(statistics.mean(BACC_collecton), 3)} ± {round(statistics.stdev(BACC_collecton), 3)}\",\n",
    "    f\"Sn: {round(statistics.mean(Sn_collecton), 3)} ± {round(statistics.stdev(Sn_collecton), 3)}\",\n",
    "    f\"Sp: {round(statistics.mean(Sp_collecton), 3)} ± {round(statistics.stdev(Sp_collecton), 3)}\",\n",
    "    f\"MCC: {round(statistics.mean(MCC_collecton), 3)} ± {round(statistics.stdev(MCC_collecton), 3)}\",\n",
    "    f\"AUC: {round(statistics.mean(AUC_collecton), 3)} ± {round(statistics.stdev(AUC_collecton), 3)}\",\n",
    "    f\"AP: {round(statistics.mean(AP), 3)} ± {round(statistics.stdev(AP), 3)}\"\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Append the results to the file\n",
    "with open('result/results_GRU.txt', 'a') as file:\n",
    "    file.write(\"----------------------------------------\\n\")\n",
    "    for result in results:\n",
    "        file.write(result + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Independence test')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('loss_curve.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制损失函数曲线\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "# 字体设置\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "n = 0\n",
    "loss = losses[n]\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(loss)\n",
    "# for i, loss in enumerate(losses):\n",
    "#     plt.plot(loss, label=f'Fold {i+1}')\n",
    "\n",
    "formatter = FuncFormatter(lambda x, pos: f'{x:.2f}')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('', fontsize=15)\n",
    "plt.title('GRU', fontsize=18)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph\\Loss\\ACE_GRU_120.jpeg', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Create a directory to save the model\n",
    "model_save_dir = 'save_models/GRU/Independence'\n",
    "\n",
    "[sample_num, input_dim] = np.shape(feature)\n",
    "X = np.reshape(feature, (-1,1,input_dim))\n",
    "\n",
    "y = label\n",
    "out_dim=2\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "_, X_ind_test, _, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=1111, stratify=y)\n",
    "\n",
    "all_predictions = []\n",
    "for i in range(10):\n",
    "    # Loading model\n",
    "    model_path = os.path.join(model_save_dir, f'model_{i+1}.h5')\n",
    "    clf = load_model(model_path)\n",
    "    print(f'Model for fold {i+1} loaded from {model_path}')\n",
    "\n",
    "    y_score = clf.predict(X_ind_test)\n",
    "    # y_class = categorical_probas_to_classes(y_score)\n",
    "    all_predictions.append(y_score)\n",
    "\n",
    "# # 转置预测结果矩阵，使每行对应一个样本的所有模型预测结果\n",
    "# all_predictions = np.array(all_predictions).T\n",
    "\n",
    "# # 多数投票\n",
    "# final_predictions = []\n",
    "# for preds in all_predictions:\n",
    "#     final_predictions.append(np.bincount(preds).argmax())\n",
    "\n",
    "# 转换为 numpy 数组\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "# 平均投票\n",
    "average_predictions = np.mean(all_predictions, axis=0)\n",
    "final_predictions = np.argmax(average_predictions, axis=1)\n",
    "\n",
    "TP, FP, FN, TN = confusion_matrix(y_ind_test, final_predictions).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "Sn_collecton = TP/(TP+FN)\n",
    "Sp_collecton = TN/(TN+FP)\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "MCC_collecton = MCC\n",
    "BACC_collecton = 0.5*TP/(TP+FN)+0.5*TN/(TN+FP)\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_ind_test, final_predictions)\n",
    "interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "interp_tpr[0] = 0.0\n",
    "interp_tpr_collection.append(interp_tpr)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "AUC_collecton = auc_roc\n",
    "# PR curve\n",
    "precision, recall, _ = precision_recall_curve(y_ind_test, final_predictions)\n",
    "average_precision = average_precision_score(y_ind_test, final_predictions)\n",
    "recall = np.flipud(recall)\n",
    "precision = np.flipud(precision)\n",
    "\n",
    "mean_precision = np.interp(mean_recall, recall, precision)\n",
    "all_precision.append(mean_precision)\n",
    "AP = average_precision\n",
    "\n",
    "\n",
    "# After all cross-validation cycles are completed, the mean TPR is calculated.\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# Output\n",
    "results = [\n",
    "    f\"BACC: {round(BACC_collecton, 3)}\",\n",
    "    f\"Sn: {round(Sn_collecton, 3)}\",\n",
    "    f\"Sp: {round(Sp_collecton, 3)}\",\n",
    "    f\"MCC: {round(MCC_collecton, 3)}\",\n",
    "    f\"AUC: {round(AUC_collecton, 3)}\",\n",
    "    f\"AP: {round(AP, 3)}\"\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Append the results to the file\n",
    "with open('result/results_GRU_Fusion_model.txt', 'a') as file:\n",
    "    file.write(\"----------------------------------------/n\")\n",
    "    for result in results:\n",
    "        file.write(result + '/n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
