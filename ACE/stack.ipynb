{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('F:/Work/Experiment/pLM4ACE/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 320)\n",
      "(1020, 1)\n",
      "394\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"fusion_features/Data/single/ESM.csv\", index_col=0, header=None)\n",
    "labels = pd.read_csv(\"fusion_features/Data/label.csv\", index_col=False, header=None)\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(np.count_nonzero(labels==0))\n",
    "print(np.count_nonzero(labels==1))\n",
    "\n",
    "feature = np.array(features)\n",
    "label = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Dense,Dropout\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, Dense,AveragePooling1D\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# model\n",
    "def CNN(input_dim, out_dim, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, padding = 'same', activation= 'relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=1,padding=\"SAME\"))\n",
    "    model.add(Conv1D(filters = 64, kernel_size =  3, padding = 'same', activation= 'relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=1,padding=\"SAME\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(int(32), activation = 'relu'))\n",
    "    model.add(Dense(out_dim, activation = 'softmax',name=\"Dense_2\"))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam_v2.Adam(learning_rate), metrics =['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要调节的参数\n",
    "# LR\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "# RF\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],   # 森林中树的数量\n",
    "#     'max_depth': [None, 10, 20, 30],  # 每棵树的最大深度\n",
    "#     'min_samples_split': [2, 5, 10],  # 分裂节点所需的最小样本数\n",
    "#     'min_samples_leaf': [1, 2, 4],    # 叶子节点的最小样本数\n",
    "#     'bootstrap': [True, False]        # 是否使用 bootstrap 样本\n",
    "# }\n",
    "# XGBoost\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "# SVM\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "# KNN\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 10],  # 邻居数量\n",
    "#     'weights': ['uniform', 'distance'],  # 权重：统一权重或根据距离加权\n",
    "#     'p': [1, 2]  # 距离度量：p=1 曼哈顿距离，p=2 欧氏距离\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model for fold 0 loaded from save_models/GRU/Independence\\ESM_0.h5\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model for fold 1 loaded from save_models/GRU/Independence\\ESM_1.h5\n",
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model for fold 2 loaded from save_models/GRU/Independence\\ESM_2.h5\n",
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model for fold 3 loaded from save_models/GRU/Independence\\ESM_3.h5\n",
      "Model for fold 4 loaded from save_models/CapsuleGAN/Independence\\ESM_4.h5\n",
      "Model for fold 5 loaded from save_models/CapsuleGAN/Independence\\ESM_5.h5\n",
      "Model for fold 6 loaded from save_models/CNN/Independence\\ESM_6.h5\n",
      "Model for fold 7 loaded from save_models/CNN/Independence\\ESM_7.h5\n",
      "Model for fold 8 loaded from save_models/CNN/Independence\\ESM_8.h5\n",
      "Model for fold 9 loaded from save_models/CapsuleGAN/Independence\\ESM_9.h5\n",
      "Best parameters:  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "BACC: 0.919\n",
      "Sn: 0.971\n",
      "Sp: 0.866\n",
      "MCC: 0.805\n",
      "AUC: 0.964\n",
      "AP: 0.974\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC  # 导入 SVM 模型\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  # 导入 KNN 模型\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  # 导入随机森林\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# Create a directory to save the model\n",
    "model_GRU_dir = 'save_models/GRU/Independence'\n",
    "model_CNN_dir = 'save_models/CNN/Independence'\n",
    "model_CapsuleGAN_dir = 'save_models/CapsuleGAN/Independence'\n",
    "\n",
    "y = label\n",
    "out_dim=2\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "# Prepare for stacking model\n",
    "stacked_features = []\n",
    "stacked_labels = []\n",
    "stacked_features_train = []\n",
    "stacked_labels_train = []\n",
    "\n",
    "for i in range(10):\n",
    "    # Loading model\n",
    "    if i in (0, 1, 2, 3):\n",
    "        [sample_num, input_dim] = np.shape(feature)\n",
    "        X = np.reshape(feature, (-1,1,input_dim))\n",
    "        X_train, X_ind_test, y_train, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "        model_path = os.path.join(model_GRU_dir, f'ESM_{i}.h5')\n",
    "        clf = load_model(model_path)\n",
    "        print(f'Model for fold {i} loaded from {model_path}')\n",
    "    elif i in (6, 7, 8):\n",
    "        [sample_num, input_dim] = np.shape(feature)\n",
    "        X = np.reshape(feature, (-1,1,input_dim))\n",
    "        X_train, X_ind_test, y_train, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "        model_path = os.path.join(model_CNN_dir, f'ESM_{i}.h5')\n",
    "        clf = load_model(model_path)\n",
    "        print(f'Model for fold {i} loaded from {model_path}')\n",
    "    else:\n",
    "        X = feature\n",
    "        X_train, X_ind_test, y_train, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "        model_path = os.path.join(model_CapsuleGAN_dir, f'ESM_{i}.h5')\n",
    "        clf = load_model(model_path)\n",
    "        print(f'Model for fold {i} loaded from {model_path}')\n",
    "\n",
    "    y_score_train = clf.predict(X_train)\n",
    "    y_score = clf.predict(X_ind_test)\n",
    "\n",
    "    # Collect features for stacking\n",
    "    if len(stacked_features) == 0:\n",
    "        stacked_features_train = y_score_train\n",
    "        stacked_labels_train = y_train\n",
    "        stacked_features = y_score\n",
    "        stacked_labels = y_ind_test\n",
    "    else:\n",
    "        stacked_features_train = np.hstack([stacked_features_train, y_score_train])\n",
    "        stacked_features = np.hstack([stacked_features, y_score])\n",
    "\n",
    "\n",
    "# [sample_num, input_dim] = np.shape(stacked_features_train)\n",
    "# stacked_features_train = np.reshape(stacked_features_train, (-1,1,input_dim))\n",
    "# stacked_features = np.reshape(stacked_features, (-1,1,input_dim))\n",
    "# out_dim=2\n",
    "# labels_train = to_categorical(y_train)\n",
    "\n",
    "# 在fit函数之前，将y_ind_test转换为一维数组\n",
    "stacked_labels_train = stacked_labels_train.ravel()\n",
    "stacked_labels = stacked_labels.ravel()\n",
    "\n",
    "# Train meta-learner (stacking classifier) with the collected features\n",
    "meta_learner = LogisticRegression(max_iter=5000)        # 逻辑回归\n",
    "# meta_learner = RandomForestClassifier()     # 随机森林\n",
    "# meta_learner = xgb.XGBClassifier(eval_metric='logloss')   # XGBoost\n",
    "# meta_learner = SVC(probability=True)\n",
    "# meta_learner = KNeighborsClassifier()\n",
    "meta_learner = GridSearchCV(meta_learner, param_grid, cv=5, scoring='balanced_accuracy')     # 最佳参数搜索\n",
    "meta_learner.fit(stacked_features_train, stacked_labels_train)\n",
    "# 输出最优参数\n",
    "print(\"Best parameters: \", meta_learner.best_params_)\n",
    "\n",
    "# meta_learner = CNN(input_dim, out_dim, 0.0005)      # CNN\n",
    "# meta_learner.fit(stacked_features_train, labels_train, batch_size=64, epochs=60)\n",
    "\n",
    "# Get final predictions from meta-learner\n",
    "# pred_score = meta_learner.predict(stacked_features)\n",
    "pred_score = meta_learner.predict_proba(stacked_features)\n",
    "final_predictions = categorical_probas_to_classes(pred_score)\n",
    "\n",
    "TP, FP, FN, TN = confusion_matrix(y_ind_test, final_predictions).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "Sn_collecton = TP/(TP+FN)\n",
    "Sp_collecton = TN/(TN+FP)\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "MCC_collecton = MCC\n",
    "BACC_collecton = 0.5*TP/(TP+FN)+0.5*TN/(TN+FP)\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_ind_test, pred_score[:, 1])\n",
    "auc_roc = auc(fpr, tpr)\n",
    "AUC_collecton = auc_roc\n",
    "# PR curve\n",
    "precision, recall, _ = precision_recall_curve(y_ind_test, pred_score[:, 1])\n",
    "average_precision = average_precision_score(y_ind_test, pred_score[:, 1])\n",
    "AP = average_precision\n",
    "\n",
    "# Output\n",
    "results = [\n",
    "    f\"BACC: {round(BACC_collecton, 3)}\",\n",
    "    f\"Sn: {round(Sn_collecton, 3)}\",\n",
    "    f\"Sp: {round(Sp_collecton, 3)}\",\n",
    "    f\"MCC: {round(MCC_collecton, 3)}\",\n",
    "    f\"AUC: {round(AUC_collecton, 3)}\",\n",
    "    f\"AP: {round(AP, 3)}\"\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Append the results to the file\n",
    "with open('result/results_Stack.txt', 'a') as file:\n",
    "    file.write(\"----------------------------------------\\n\")\n",
    "    for result in results:\n",
    "        file.write(result + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ROC曲线相关参数\n",
    "np.savez('graph/ACE/ROC/Stack.npz', fpr=fpr, tpr=tpr, roc_auc=AUC_collecton)\n",
    "\n",
    "# 保存PR曲线相关参数\n",
    "np.savez('graph/ACE/PR/Stack.npz', recall=recall, precision=precision, average_precision=AP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
