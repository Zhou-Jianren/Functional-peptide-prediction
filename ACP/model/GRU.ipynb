{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('F:/One/ACP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (1378, 320)\n",
      "train_labels (1378, 1)\n",
      "test_features (344, 320)\n",
      "test_labels (344, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# train\n",
    "train_features = pd.read_csv(\"features_label/train.csv\", index_col=False, header=None)\n",
    "train_labels = pd.read_csv(\"features_label/train_label.csv\", index_col=False, header=None)\n",
    "# test\n",
    "test_features = pd.read_csv(\"features_label/test.csv\", index_col=False, header=None)\n",
    "test_labels = pd.read_csv(\"features_label/test_label.csv\", index_col=False, header=None)\n",
    "\n",
    "print('train_features:', train_features.shape)\n",
    "print('train_labels', train_labels.shape)\n",
    "print('test_features', test_features.shape)\n",
    "print('test_labels', test_labels.shape)\n",
    "\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# model\n",
    "def get_GRU_model(input_dim, out_dim, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(64, return_sequences=True, input_shape=(1, input_dim)))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(GRU(64, return_sequences=True))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu', name=\"Dense_128\"))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(2, activation='softmax', name=\"Dense_2\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(learning_rate), metrics=['accuracy'])  # rmsprop\n",
    "    return model\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the model\n",
    "model_save_dir = 'save_models/GRU/Independence'\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "22/22 [==============================] - 8s 29ms/step - loss: 0.6863 - accuracy: 0.5704\n",
      "Epoch 2/120\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.6645 - accuracy: 0.6328\n",
      "Epoch 3/120\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.6338 - accuracy: 0.6582\n",
      "Epoch 4/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.6095 - accuracy: 0.6662\n",
      "Epoch 5/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5984 - accuracy: 0.6778\n",
      "Epoch 6/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5881 - accuracy: 0.6771\n",
      "Epoch 7/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5769 - accuracy: 0.6821\n",
      "Epoch 8/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5713 - accuracy: 0.6872\n",
      "Epoch 9/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5578 - accuracy: 0.6930\n",
      "Epoch 10/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5500 - accuracy: 0.7083\n",
      "Epoch 11/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5482 - accuracy: 0.7075\n",
      "Epoch 12/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5410 - accuracy: 0.7177\n",
      "Epoch 13/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5418 - accuracy: 0.7097\n",
      "Epoch 14/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5316 - accuracy: 0.7155\n",
      "Epoch 15/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5261 - accuracy: 0.7271\n",
      "Epoch 16/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5208 - accuracy: 0.7300\n",
      "Epoch 17/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.5154 - accuracy: 0.7366\n",
      "Epoch 18/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5144 - accuracy: 0.7344\n",
      "Epoch 19/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.5116 - accuracy: 0.7293\n",
      "Epoch 20/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5099 - accuracy: 0.7366\n",
      "Epoch 21/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5104 - accuracy: 0.7315\n",
      "Epoch 22/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5005 - accuracy: 0.7395\n",
      "Epoch 23/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4976 - accuracy: 0.7496\n",
      "Epoch 24/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4932 - accuracy: 0.7598\n",
      "Epoch 25/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4998 - accuracy: 0.7460\n",
      "Epoch 26/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4908 - accuracy: 0.7612\n",
      "Epoch 27/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4794 - accuracy: 0.7634\n",
      "Epoch 28/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4735 - accuracy: 0.7685\n",
      "Epoch 29/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4750 - accuracy: 0.7663\n",
      "Epoch 30/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4657 - accuracy: 0.7678\n",
      "Epoch 31/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4689 - accuracy: 0.7678\n",
      "Epoch 32/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4681 - accuracy: 0.7685\n",
      "Epoch 33/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4585 - accuracy: 0.7837\n",
      "Epoch 34/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4552 - accuracy: 0.7823\n",
      "Epoch 35/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4514 - accuracy: 0.7765\n",
      "Epoch 36/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4533 - accuracy: 0.7787\n",
      "Epoch 37/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4481 - accuracy: 0.7845\n",
      "Epoch 38/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4470 - accuracy: 0.7779\n",
      "Epoch 39/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4356 - accuracy: 0.7932\n",
      "Epoch 40/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4347 - accuracy: 0.7896\n",
      "Epoch 41/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4345 - accuracy: 0.7939\n",
      "Epoch 42/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4312 - accuracy: 0.7954\n",
      "Epoch 43/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4281 - accuracy: 0.7975\n",
      "Epoch 44/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4168 - accuracy: 0.8084\n",
      "Epoch 45/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4171 - accuracy: 0.8012\n",
      "Epoch 46/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4192 - accuracy: 0.7983\n",
      "Epoch 47/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4168 - accuracy: 0.7990\n",
      "Epoch 48/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4021 - accuracy: 0.8171\n",
      "Epoch 49/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4162 - accuracy: 0.8019\n",
      "Epoch 50/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4065 - accuracy: 0.8033\n",
      "Epoch 51/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.4015 - accuracy: 0.8135\n",
      "Epoch 52/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4080 - accuracy: 0.8215\n",
      "Epoch 53/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3917 - accuracy: 0.8193\n",
      "Epoch 54/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3940 - accuracy: 0.8193\n",
      "Epoch 55/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3869 - accuracy: 0.8258\n",
      "Epoch 56/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.8164\n",
      "Epoch 57/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3867 - accuracy: 0.8295\n",
      "Epoch 58/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3790 - accuracy: 0.8251\n",
      "Epoch 59/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3886 - accuracy: 0.8186\n",
      "Epoch 60/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3853 - accuracy: 0.8309\n",
      "Epoch 61/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3711 - accuracy: 0.8345\n",
      "Epoch 62/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3876 - accuracy: 0.8113\n",
      "Epoch 63/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3731 - accuracy: 0.8374\n",
      "Epoch 64/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3644 - accuracy: 0.8302\n",
      "Epoch 65/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3620 - accuracy: 0.8345\n",
      "Epoch 66/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3681 - accuracy: 0.8345\n",
      "Epoch 67/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.3547 - accuracy: 0.8469\n",
      "Epoch 68/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3480 - accuracy: 0.8462\n",
      "Epoch 69/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3671 - accuracy: 0.8244\n",
      "Epoch 70/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3493 - accuracy: 0.8418\n",
      "Epoch 71/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3634 - accuracy: 0.8425\n",
      "Epoch 72/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3491 - accuracy: 0.8396\n",
      "Epoch 73/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3501 - accuracy: 0.8447\n",
      "Epoch 74/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3453 - accuracy: 0.8469\n",
      "Epoch 75/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3408 - accuracy: 0.8491\n",
      "Epoch 76/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3372 - accuracy: 0.8549\n",
      "Epoch 77/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3405 - accuracy: 0.8527\n",
      "Epoch 78/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3419 - accuracy: 0.8527\n",
      "Epoch 79/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3250 - accuracy: 0.8563\n",
      "Epoch 80/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3318 - accuracy: 0.8585\n",
      "Epoch 81/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3364 - accuracy: 0.8534\n",
      "Epoch 82/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3203 - accuracy: 0.8679\n",
      "Epoch 83/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3281 - accuracy: 0.8614\n",
      "Epoch 84/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3253 - accuracy: 0.8556\n",
      "Epoch 85/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3133 - accuracy: 0.8636\n",
      "Epoch 86/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3139 - accuracy: 0.8628\n",
      "Epoch 87/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3273 - accuracy: 0.8585\n",
      "Epoch 88/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3428 - accuracy: 0.8563\n",
      "Epoch 89/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3141 - accuracy: 0.8599\n",
      "Epoch 90/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3246 - accuracy: 0.8534\n",
      "Epoch 91/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3142 - accuracy: 0.8599\n",
      "Epoch 92/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3114 - accuracy: 0.8679\n",
      "Epoch 93/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2993 - accuracy: 0.8694\n",
      "Epoch 94/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2984 - accuracy: 0.8650\n",
      "Epoch 95/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2846 - accuracy: 0.8665\n",
      "Epoch 96/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3075 - accuracy: 0.8657\n",
      "Epoch 97/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3068 - accuracy: 0.8716\n",
      "Epoch 98/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2940 - accuracy: 0.8723\n",
      "Epoch 99/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3039 - accuracy: 0.8716\n",
      "Epoch 100/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3118 - accuracy: 0.8621\n",
      "Epoch 101/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3072 - accuracy: 0.8628\n",
      "Epoch 102/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.3049 - accuracy: 0.8592\n",
      "Epoch 103/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2997 - accuracy: 0.8737\n",
      "Epoch 104/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2994 - accuracy: 0.8766\n",
      "Epoch 105/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2758 - accuracy: 0.8788\n",
      "Epoch 106/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2833 - accuracy: 0.8752\n",
      "Epoch 107/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2849 - accuracy: 0.8774\n",
      "Epoch 108/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2760 - accuracy: 0.8788\n",
      "Epoch 109/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2857 - accuracy: 0.8766\n",
      "Epoch 110/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2783 - accuracy: 0.8795\n",
      "Epoch 111/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2757 - accuracy: 0.8868\n",
      "Epoch 112/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2701 - accuracy: 0.8861\n",
      "Epoch 113/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2742 - accuracy: 0.8853\n",
      "Epoch 114/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2689 - accuracy: 0.8868\n",
      "Epoch 115/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2659 - accuracy: 0.8875\n",
      "Epoch 116/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2671 - accuracy: 0.8846\n",
      "Epoch 117/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2696 - accuracy: 0.8832\n",
      "Epoch 118/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.2858 - accuracy: 0.8759\n",
      "Epoch 119/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.2716 - accuracy: 0.8962\n",
      "Epoch 120/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.2622 - accuracy: 0.8933\n",
      "Epoch 1/120\n",
      "22/22 [==============================] - 5s 19ms/step - loss: 0.6905 - accuracy: 0.5414\n",
      "Epoch 2/120\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.6665 - accuracy: 0.6437\n",
      "Epoch 3/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6375 - accuracy: 0.6611\n",
      "Epoch 4/120\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.6127 - accuracy: 0.6611\n",
      "Epoch 5/120\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5978 - accuracy: 0.6720\n",
      "Epoch 6/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5867 - accuracy: 0.6763\n",
      "Epoch 7/120\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5748 - accuracy: 0.6829\n",
      "Epoch 8/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5656 - accuracy: 0.7039\n",
      "Epoch 9/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.5603 - accuracy: 0.6996\n",
      "Epoch 10/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.5551 - accuracy: 0.7017\n",
      "Epoch 11/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.5431 - accuracy: 0.7221\n",
      "Epoch 12/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.5420 - accuracy: 0.7104\n",
      "Epoch 13/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5393 - accuracy: 0.7134\n",
      "Epoch 14/120\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5421 - accuracy: 0.7141\n",
      "Epoch 15/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5317 - accuracy: 0.7235\n",
      "Epoch 16/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5241 - accuracy: 0.7322\n",
      "Epoch 17/120\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5324 - accuracy: 0.7192\n",
      "Epoch 18/120\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.5202 - accuracy: 0.7388\n",
      "Epoch 19/120\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5161 - accuracy: 0.7358\n",
      "Epoch 20/120\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.5136 - accuracy: 0.7337\n",
      "Epoch 21/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5097 - accuracy: 0.7460\n",
      "Epoch 22/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5038 - accuracy: 0.7446\n",
      "Epoch 23/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4964 - accuracy: 0.7504\n",
      "Epoch 24/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4999 - accuracy: 0.7409\n",
      "Epoch 25/120\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.4888 - accuracy: 0.7496\n",
      "Epoch 26/120\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 0.4892 - accuracy: 0.7511\n",
      "Epoch 27/120\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.4920 - accuracy: 0.7569\n",
      "Epoch 28/120\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.4828 - accuracy: 0.7605\n",
      "Epoch 29/120\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.4768 - accuracy: 0.7678\n",
      "Epoch 30/120\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.4721 - accuracy: 0.7656\n",
      "Epoch 31/120\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.4723 - accuracy: 0.7743\n",
      "Epoch 32/120\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.4709 - accuracy: 0.7714\n",
      "Epoch 33/120\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.4763 - accuracy: 0.7620\n",
      "Epoch 34/120\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4711 - accuracy: 0.7765\n",
      "Epoch 35/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4567 - accuracy: 0.7765\n",
      "Epoch 36/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4484 - accuracy: 0.7888\n",
      "Epoch 37/120\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4489 - accuracy: 0.7932\n",
      "Epoch 38/120\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.4455 - accuracy: 0.7859\n",
      "Epoch 39/120\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4464 - accuracy: 0.7859\n",
      "Epoch 40/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4420 - accuracy: 0.7874\n",
      "Epoch 41/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4371 - accuracy: 0.7990\n",
      "Epoch 42/120\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4310 - accuracy: 0.8026\n",
      "Epoch 43/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4263 - accuracy: 0.7946\n",
      "Epoch 44/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4316 - accuracy: 0.8041\n",
      "Epoch 45/120\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.4263 - accuracy: 0.7946\n",
      "Epoch 46/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4291 - accuracy: 0.7961\n",
      "Epoch 47/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4227 - accuracy: 0.8113\n",
      "Epoch 48/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4142 - accuracy: 0.8033\n",
      "Epoch 49/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4199 - accuracy: 0.8033\n",
      "Epoch 50/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4089 - accuracy: 0.8149\n",
      "Epoch 51/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4096 - accuracy: 0.8149\n",
      "Epoch 52/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4089 - accuracy: 0.8084\n",
      "Epoch 53/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.3992 - accuracy: 0.8120\n",
      "Epoch 54/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4112 - accuracy: 0.8048\n",
      "Epoch 55/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.3904 - accuracy: 0.8171\n",
      "Epoch 56/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3912 - accuracy: 0.8273\n",
      "Epoch 57/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.3876 - accuracy: 0.8251\n",
      "Epoch 58/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3937 - accuracy: 0.8338\n",
      "Epoch 59/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3998 - accuracy: 0.8171\n",
      "Epoch 60/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3822 - accuracy: 0.8266\n",
      "Epoch 61/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.3809 - accuracy: 0.8280\n",
      "Epoch 62/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3823 - accuracy: 0.8222\n",
      "Epoch 63/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3722 - accuracy: 0.8302\n",
      "Epoch 64/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3663 - accuracy: 0.8382\n",
      "Epoch 65/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3706 - accuracy: 0.8331\n",
      "Epoch 66/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3672 - accuracy: 0.8382\n",
      "Epoch 67/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3607 - accuracy: 0.8360\n",
      "Epoch 68/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3646 - accuracy: 0.8382\n",
      "Epoch 69/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3597 - accuracy: 0.8411\n",
      "Epoch 70/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3686 - accuracy: 0.8353\n",
      "Epoch 71/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3555 - accuracy: 0.8440\n",
      "Epoch 72/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3548 - accuracy: 0.8454\n",
      "Epoch 73/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3498 - accuracy: 0.8621\n",
      "Epoch 74/120\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3681 - accuracy: 0.8302\n",
      "Epoch 75/120\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.3720 - accuracy: 0.8345\n",
      "Epoch 76/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.3562 - accuracy: 0.8491\n",
      "Epoch 77/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3469 - accuracy: 0.8534\n",
      "Epoch 78/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3395 - accuracy: 0.8541\n",
      "Epoch 79/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3344 - accuracy: 0.8585\n",
      "Epoch 80/120\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3375 - accuracy: 0.8520\n",
      "Epoch 81/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.3294 - accuracy: 0.8578\n",
      "Epoch 82/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3280 - accuracy: 0.8570\n",
      "Epoch 83/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3193 - accuracy: 0.8672\n",
      "Epoch 84/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3245 - accuracy: 0.8614\n",
      "Epoch 85/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3268 - accuracy: 0.8607\n",
      "Epoch 86/120\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.3280 - accuracy: 0.8592\n",
      "Epoch 87/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3176 - accuracy: 0.8745\n",
      "Epoch 88/120\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.3198 - accuracy: 0.8628\n",
      "Epoch 89/120\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.3078 - accuracy: 0.8730\n",
      "Epoch 90/120\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.3116 - accuracy: 0.8628\n",
      "Epoch 91/120\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3125 - accuracy: 0.8650\n",
      "Epoch 92/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2932 - accuracy: 0.8810\n",
      "Epoch 93/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.3058 - accuracy: 0.8737\n",
      "Epoch 94/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.3058 - accuracy: 0.8672\n",
      "Epoch 95/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.3003 - accuracy: 0.8766\n",
      "Epoch 96/120\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.3095 - accuracy: 0.8643\n",
      "Epoch 97/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2972 - accuracy: 0.8679\n",
      "Epoch 98/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2919 - accuracy: 0.8759\n",
      "Epoch 99/120\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.3162 - accuracy: 0.8694\n",
      "Epoch 100/120\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.2972 - accuracy: 0.8788\n",
      "Epoch 101/120\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.2819 - accuracy: 0.8839\n",
      "Epoch 102/120\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.3051 - accuracy: 0.8708\n",
      "Epoch 103/120\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.2788 - accuracy: 0.8817\n",
      "Epoch 104/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2843 - accuracy: 0.8810\n",
      "Epoch 105/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2857 - accuracy: 0.8759\n",
      "Epoch 106/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2795 - accuracy: 0.8839\n",
      "Epoch 107/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2739 - accuracy: 0.8897\n",
      "Epoch 108/120\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.2755 - accuracy: 0.8853\n",
      "Epoch 109/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2723 - accuracy: 0.8839\n",
      "Epoch 110/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2841 - accuracy: 0.8803\n",
      "Epoch 111/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2852 - accuracy: 0.8781\n",
      "Epoch 112/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2698 - accuracy: 0.8861\n",
      "Epoch 113/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2541 - accuracy: 0.8977\n",
      "Epoch 114/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2642 - accuracy: 0.8861\n",
      "Epoch 115/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2692 - accuracy: 0.8933\n",
      "Epoch 116/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2633 - accuracy: 0.8853\n",
      "Epoch 117/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2621 - accuracy: 0.8911\n",
      "Epoch 118/120\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2624 - accuracy: 0.8882\n",
      "Epoch 119/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2522 - accuracy: 0.8933\n",
      "Epoch 120/120\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.2443 - accuracy: 0.9020\n",
      "ACC: 0.733 ± 0.004\n",
      "BACC: 0.734 ± 0.005\n",
      "Sn: 0.731 ± 0.02\n",
      "Sp: 0.737 ± 0.03\n",
      "MCC: 0.466 ± 0.009\n",
      "AUC: 0.809 ± 0.008\n",
      "AP: 0.824 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "[sample_num, input_dim] = np.shape(train_features)\n",
    "X_train = np.reshape(train_features, (-1,1,input_dim))\n",
    "y_train = train_labels\n",
    "X_test = np.reshape(test_features, (-1,1,input_dim))\n",
    "y_test = test_labels\n",
    "out_dim=2\n",
    "\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "\n",
    "losses = []  # Used to store the loss value of each fold\n",
    "for i in range(2):\n",
    "    # dataset\n",
    "    y_train_whole = to_categorical(y_train)\n",
    "    \n",
    "    clf = get_GRU_model(input_dim, out_dim, 0.0005)\n",
    "    hist = clf.fit(X_train, y_train_whole, batch_size=64, epochs=120)\n",
    "\n",
    "    # save model\n",
    "    # model_path = os.path.join(model_save_dir, f'ESM_{i}.h5')\n",
    "    # clf.save(model_path)\n",
    "    # print(f'Model for fold {i+1} saved at {model_path}')\n",
    "\n",
    "    losses.append(hist.history['loss'])  # Record the loss value of each epoch\n",
    "\n",
    "    y_score = clf.predict(X_test)\n",
    "    y_class = categorical_probas_to_classes(y_score)\n",
    "    TP, FP, FN, TN = confusion_matrix(y_test, y_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "    ACC_collecton.append(ACC)\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    AUC_collecton.append(auc_roc)\n",
    "    # PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score[:, 1])\n",
    "    average_precision = average_precision_score(y_test, y_score[:, 1])\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "    mean_precision = np.interp(mean_recall, recall, precision)\n",
    "    all_precision.append(mean_precision)\n",
    "    AP.append(average_precision)\n",
    "\n",
    "\n",
    "# After all cross-validation cycles are completed, the mean TPR is calculated.\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# Output\n",
    "results = [\n",
    "    f\"ACC: {round(statistics.mean(ACC_collecton), 3)} ± {round(statistics.stdev(ACC_collecton), 3)}\",\n",
    "    f\"BACC: {round(statistics.mean(BACC_collecton), 3)} ± {round(statistics.stdev(BACC_collecton), 3)}\",\n",
    "    f\"Sn: {round(statistics.mean(Sn_collecton), 3)} ± {round(statistics.stdev(Sn_collecton), 3)}\",\n",
    "    f\"Sp: {round(statistics.mean(Sp_collecton), 3)} ± {round(statistics.stdev(Sp_collecton), 3)}\",\n",
    "    f\"MCC: {round(statistics.mean(MCC_collecton), 3)} ± {round(statistics.stdev(MCC_collecton), 3)}\",\n",
    "    f\"AUC: {round(statistics.mean(AUC_collecton), 3)} ± {round(statistics.stdev(AUC_collecton), 3)}\",\n",
    "    f\"AP: {round(statistics.mean(AP), 3)} ± {round(statistics.stdev(AP), 3)}\"\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Append the results to the file\n",
    "with open('result/results_GRU.txt', 'a') as file:\n",
    "    file.write(\"----------------------------------------\\n\")\n",
    "    for result in results:\n",
    "        file.write(result + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Independence test')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('loss_curve.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制损失函数曲线\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "# 字体设置\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "n = 0\n",
    "loss = losses[n]\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(loss)\n",
    "# for i, loss in enumerate(losses):\n",
    "#     plt.plot(loss, label=f'Fold {i+1}')\n",
    "\n",
    "formatter = FuncFormatter(lambda x, pos: f'{x:.2f}')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('', fontsize=15)\n",
    "plt.title('GRU', fontsize=18)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph\\Loss\\ACP_GRU_120.jpeg', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Create a directory to save the model\n",
    "model_save_dir = 'save_models/GRU/Independence'\n",
    "\n",
    "[sample_num, input_dim] = np.shape(feature)\n",
    "X = np.reshape(feature, (-1,1,input_dim))\n",
    "\n",
    "y = label\n",
    "out_dim=2\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "_, X_ind_test, _, y_ind_test = train_test_split(X, y, test_size=0.2, random_state=1111, stratify=y)\n",
    "\n",
    "all_predictions = []\n",
    "for i in range(10):\n",
    "    # Loading model\n",
    "    model_path = os.path.join(model_save_dir, f'model_{i+1}.h5')\n",
    "    clf = load_model(model_path)\n",
    "    print(f'Model for fold {i+1} loaded from {model_path}')\n",
    "\n",
    "    y_score = clf.predict(X_ind_test)\n",
    "    # y_class = categorical_probas_to_classes(y_score)\n",
    "    all_predictions.append(y_score)\n",
    "\n",
    "# # 转置预测结果矩阵，使每行对应一个样本的所有模型预测结果\n",
    "# all_predictions = np.array(all_predictions).T\n",
    "\n",
    "# # 多数投票\n",
    "# final_predictions = []\n",
    "# for preds in all_predictions:\n",
    "#     final_predictions.append(np.bincount(preds).argmax())\n",
    "\n",
    "# 转换为 numpy 数组\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "# 平均投票\n",
    "average_predictions = np.mean(all_predictions, axis=0)\n",
    "final_predictions = np.argmax(average_predictions, axis=1)\n",
    "\n",
    "TP, FP, FN, TN = confusion_matrix(y_ind_test, final_predictions).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "Sn_collecton = TP/(TP+FN)\n",
    "Sp_collecton = TN/(TN+FP)\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "MCC_collecton = MCC\n",
    "BACC_collecton = 0.5*TP/(TP+FN)+0.5*TN/(TN+FP)\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_ind_test, final_predictions)\n",
    "interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "interp_tpr[0] = 0.0\n",
    "interp_tpr_collection.append(interp_tpr)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "AUC_collecton = auc_roc\n",
    "# PR curve\n",
    "precision, recall, _ = precision_recall_curve(y_ind_test, final_predictions)\n",
    "average_precision = average_precision_score(y_ind_test, final_predictions)\n",
    "recall = np.flipud(recall)\n",
    "precision = np.flipud(precision)\n",
    "\n",
    "mean_precision = np.interp(mean_recall, recall, precision)\n",
    "all_precision.append(mean_precision)\n",
    "AP = average_precision\n",
    "\n",
    "\n",
    "# After all cross-validation cycles are completed, the mean TPR is calculated.\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# Output\n",
    "results = [\n",
    "    f\"BACC: {round(BACC_collecton, 3)}\",\n",
    "    f\"Sn: {round(Sn_collecton, 3)}\",\n",
    "    f\"Sp: {round(Sp_collecton, 3)}\",\n",
    "    f\"MCC: {round(MCC_collecton, 3)}\",\n",
    "    f\"AUC: {round(AUC_collecton, 3)}\",\n",
    "    f\"AP: {round(AP, 3)}\"\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Append the results to the file\n",
    "with open('result/results_GRU_Fusion_model.txt', 'a') as file:\n",
    "    file.write(\"----------------------------------------/n\")\n",
    "    for result in results:\n",
    "        file.write(result + '/n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
