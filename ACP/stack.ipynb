{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('F:/One/ACP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (1378, 320)\n",
      "train_labels (1378, 1)\n",
      "test_features (344, 320)\n",
      "test_labels (344, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# train\n",
    "train_features = pd.read_csv(\"features_label/train.csv\", index_col=False, header=None)\n",
    "train_labels = pd.read_csv(\"features_label/train_label.csv\", index_col=False, header=None)\n",
    "# test\n",
    "test_features = pd.read_csv(\"features_label/test.csv\", index_col=False, header=None)\n",
    "test_labels = pd.read_csv(\"features_label/test_label.csv\", index_col=False, header=None)\n",
    "\n",
    "print('train_features:', train_features.shape)\n",
    "print('train_labels', train_labels.shape)\n",
    "print('test_features', test_features.shape)\n",
    "print('test_labels', test_labels.shape)\n",
    "\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Dense,Dropout\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, Dense,AveragePooling1D\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# model\n",
    "def CNN(input_dim, out_dim, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, padding = 'same', activation= 'relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=1,padding=\"SAME\"))\n",
    "    model.add(Conv1D(filters = 64, kernel_size =  3, padding = 'same', activation= 'relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=1,padding=\"SAME\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(int(32), activation = 'relu'))\n",
    "    model.add(Dense(out_dim, activation = 'softmax',name=\"Dense_2\"))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam_v2.Adam(learning_rate), metrics =['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要调节的参数\n",
    "# LR\n",
    "# param_grid = {\n",
    "#     'penalty': ['l2', 'l1'],\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'solver': ['liblinear', 'saga']\n",
    "# }\n",
    "# RF\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],   # 森林中树的数量\n",
    "#     'max_depth': [None, 10, 20, 30],  # 每棵树的最大深度\n",
    "#     'min_samples_split': [2, 5, 10],  # 分裂节点所需的最小样本数\n",
    "#     'min_samples_leaf': [1, 2, 4],    # 叶子节点的最小样本数\n",
    "#     'bootstrap': [True, False]        # 是否使用 bootstrap 样本\n",
    "# }\n",
    "# XGBoost\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "# SVM\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "# KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10],  # 邻居数量\n",
    "    'weights': ['uniform', 'distance'],  # 权重：统一权重或根据距离加权\n",
    "    'p': [1, 2]  # 距离度量：p=1 曼哈顿距离，p=2 欧氏距离\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model for fold 0 loaded from save_models/GRU/Independence\\ESM_0.h5\n",
      "WARNING:tensorflow:Layer gru_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model for fold 1 loaded from save_models/GRU/Independence\\ESM_1.h5\n",
      "Model for fold 2 loaded from save_models/CNN/Independence\\ESM_2.h5\n",
      "Model for fold 3 loaded from save_models/CNN/Independence\\ESM_3.h5\n",
      "Model for fold 4 loaded from save_models/CNN/Independence\\ESM_4.h5\n",
      "Model for fold 5 loaded from save_models/CNN/Independence\\ESM_5.h5\n",
      "Model for fold 6 loaded from save_models/CNN/Independence\\ESM_6.h5\n",
      "Model for fold 7 loaded from save_models/CNN/Independence\\ESM_7.h5\n",
      "Model for fold 8 loaded from save_models/CapsuleGAN/Independence\\ESM_8.h5\n",
      "Model for fold 9 loaded from save_models/CapsuleGAN/Independence\\ESM_9.h5\n",
      "Epoch 1/30\n",
      "22/22 [==============================] - 4s 15ms/step - loss: 0.6690 - binary_accuracy: 0.6988\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6435 - binary_accuracy: 0.8650\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6157 - binary_accuracy: 0.8716\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5867 - binary_accuracy: 0.8737\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5569 - binary_accuracy: 0.8766\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5259 - binary_accuracy: 0.8781\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4951 - binary_accuracy: 0.8788\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4647 - binary_accuracy: 0.8810\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4350 - binary_accuracy: 0.8824\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - binary_accuracy: 0.8861\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3813 - binary_accuracy: 0.8926\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3578 - binary_accuracy: 0.8940\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3369 - binary_accuracy: 0.8955\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3197 - binary_accuracy: 0.8948\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3057 - binary_accuracy: 0.8904\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2950 - binary_accuracy: 0.8926\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2862 - binary_accuracy: 0.8948\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2801 - binary_accuracy: 0.8948\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2754 - binary_accuracy: 0.8955\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2715 - binary_accuracy: 0.8948\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2688 - binary_accuracy: 0.8955\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2664 - binary_accuracy: 0.8955\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2652 - binary_accuracy: 0.8962\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2632 - binary_accuracy: 0.8948\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2622 - binary_accuracy: 0.8955\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2612 - binary_accuracy: 0.8948\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2603 - binary_accuracy: 0.8955\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2596 - binary_accuracy: 0.8955\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2585 - binary_accuracy: 0.8940\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2580 - binary_accuracy: 0.8948\n",
      "ACC: 0.782\n",
      "BACC: 0.782\n",
      "Sn: 0.794\n",
      "Sp: 0.771\n",
      "MCC: 0.564\n",
      "AUC: 0.83\n",
      "AP: 0.849\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC  # 导入 SVM 模型\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  # 导入 KNN 模型\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier  # 导入随机森林\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# Create a directory to save the model\n",
    "model_GRU_dir = 'save_models/GRU/Independence'\n",
    "model_CNN_dir = 'save_models/CNN/Independence'\n",
    "model_CapsuleGAN_dir = 'save_models/CapsuleGAN/Independence'\n",
    "\n",
    "[sample_num, input_dim] = np.shape(train_features)\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "out_dim=2\n",
    "\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "\n",
    "# Prepare for stacking model\n",
    "stacked_features = []\n",
    "stacked_labels = []\n",
    "stacked_features_train = []\n",
    "stacked_labels_train = []\n",
    "\n",
    "for i in range(10):\n",
    "    # Loading model\n",
    "    if i in (0, 1):\n",
    "        X_train = np.reshape(train_features, (-1,1,input_dim))\n",
    "        X_test = np.reshape(test_features, (-1,1,input_dim))\n",
    "\n",
    "        model_path = os.path.join(model_GRU_dir, f'ESM_{i}.h5')\n",
    "        clf = load_model(model_path)\n",
    "        print(f'Model for fold {i} loaded from {model_path}')\n",
    "    elif i in (2, 3, 4, 5, 6, 7):\n",
    "        X_train = np.reshape(train_features, (-1,1,input_dim))\n",
    "        X_test = np.reshape(test_features, (-1,1,input_dim))\n",
    "\n",
    "        model_path = os.path.join(model_CNN_dir, f'ESM_{i}.h5')\n",
    "        clf = load_model(model_path)\n",
    "        print(f'Model for fold {i} loaded from {model_path}')\n",
    "    else:\n",
    "        X_train = train_features\n",
    "        X_test = test_features\n",
    "\n",
    "        model_path = os.path.join(model_CapsuleGAN_dir, f'ESM_{i}.h5')\n",
    "        clf = load_model(model_path)\n",
    "        print(f'Model for fold {i} loaded from {model_path}')\n",
    "\n",
    "    y_score_train = clf.predict(X_train)\n",
    "    y_score = clf.predict(X_test)\n",
    "\n",
    "    # Collect features for stacking\n",
    "    if len(stacked_features) == 0:\n",
    "        stacked_features_train = y_score_train\n",
    "        stacked_features = y_score\n",
    "        stacked_labels_train = y_train\n",
    "        stacked_labels = y_test\n",
    "    else:\n",
    "        stacked_features_train = np.hstack([stacked_features_train, y_score_train])\n",
    "        stacked_features = np.hstack([stacked_features, y_score])\n",
    "\n",
    "\n",
    "[sample_num, input_dim] = np.shape(stacked_features_train)\n",
    "stacked_features_train = np.reshape(stacked_features_train, (-1,1,input_dim))\n",
    "stacked_features = np.reshape(stacked_features, (-1,1,input_dim))\n",
    "out_dim=2\n",
    "labels_train = to_categorical(y_train)\n",
    "\n",
    "# 在fit函数之前，将y_ind_test转换为一维数组\n",
    "# stacked_labels_train = stacked_labels_train.ravel()\n",
    "# stacked_labels = stacked_labels.ravel()\n",
    "\n",
    "# Train meta-learner (stacking classifier) with the collected features\n",
    "# meta_learner = LogisticRegression(max_iter=5000)        # 逻辑回归\n",
    "# meta_learner = RandomForestClassifier()     # 随机森林\n",
    "# meta_learner = xgb.XGBClassifier(eval_metric='logloss')   # XGBoost\n",
    "# meta_learner = SVC(probability=True)\n",
    "# meta_learner = KNeighborsClassifier()\n",
    "# meta_learner = GridSearchCV(meta_learner, param_grid, cv=5, scoring='accuracy')     # 最佳参数搜索\n",
    "# meta_learner.fit(stacked_features_train, stacked_labels_train)\n",
    "# 输出最优参数\n",
    "# print(\"Best parameters: \", meta_learner.best_params_)\n",
    "\n",
    "meta_learner = CNN(input_dim, out_dim, 0.0001)      # CNN\n",
    "meta_learner.fit(stacked_features_train, labels_train, batch_size=64, epochs=30)\n",
    "\n",
    "\n",
    "# Get final predictions from meta-learner\n",
    "# DL\n",
    "pred_score = meta_learner.predict(stacked_features)\n",
    "# ML\n",
    "# pred_score = meta_learner.predict_proba(stacked_features)\n",
    "final_predictions = categorical_probas_to_classes(pred_score)\n",
    "\n",
    "TP, FP, FN, TN = confusion_matrix(y_test, final_predictions).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "Sn_collecton = TP/(TP+FN)\n",
    "Sp_collecton = TN/(TN+FP)\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "MCC_collecton = MCC\n",
    "BACC_collecton = 0.5*TP/(TP+FN)+0.5*TN/(TN+FP)\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC_collecton = ACC\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, pred_score[:, 1])\n",
    "auc_roc = auc(fpr, tpr)\n",
    "AUC_collecton = auc_roc\n",
    "# PR curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, pred_score[:, 1])\n",
    "average_precision = average_precision_score(y_test, pred_score[:, 1])\n",
    "AP = average_precision\n",
    "\n",
    "# Output\n",
    "results = [\n",
    "    f\"ACC: {round(ACC_collecton, 3)}\",\n",
    "    f\"BACC: {round(BACC_collecton, 3)}\",\n",
    "    f\"Sn: {round(Sn_collecton, 3)}\",\n",
    "    f\"Sp: {round(Sp_collecton, 3)}\",\n",
    "    f\"MCC: {round(MCC_collecton, 3)}\",\n",
    "    f\"AUC: {round(AUC_collecton, 3)}\",\n",
    "    f\"AP: {round(AP, 3)}\"\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Append the results to the file\n",
    "with open('result/results_Stack.txt', 'a') as file:\n",
    "    file.write(\"----------------------------------------\\n\")\n",
    "    for result in results:\n",
    "        file.write(result + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ROC曲线相关参数\n",
    "np.savez('graph/ROC/Stack.npz', fpr=fpr, tpr=tpr, roc_auc=AUC_collecton)\n",
    "\n",
    "# 保存PR曲线相关参数\n",
    "np.savez('graph/PR/Stack.npz', recall=recall, precision=precision, average_precision=AP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
